{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Predicting creditcards approval v2\r\n",
    "\r\n",
    "Plan\r\n",
    "1. Data already cleaned from previous notebook\r\n",
    "2. EDA\r\n",
    "3. Come up with some sense of the dataset before going into building models\r\n",
    "4. Define problem statement and come up with assumptions\r\n",
    "<br>\r\n",
    "<br>\r\n",
    "5. Preprocessing what more can we do - dimensional reduction, NMF??\r\n",
    "6. Fine tune each model's parameters to squeeze out the best for each model\r\n",
    "7. Compare different classification models - knn, logistic regression "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get data from cleaned source"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import packages\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "# read csv\r\n",
    "df = pd.read_csv('cc_approvals_cleaned.csv')\r\n",
    "print(df.head())\r\n",
    "print('-'*40)\r\n",
    "print(df.info())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# change zipcode to string again, got reseted when reloaded csv\r\n",
    "df.ZipCode = df.ZipCode.astype('str')\r\n",
    "print(df.info())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem statement\r\n",
    "1. Who are our creditcards customers?\r\n",
    "2. Which features influenced approval decision?\r\n",
    "3. Given application data, develop a classification model to predict creditcard approval to save manual application revision time.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## EDA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Most of applicants are under 40 years old\r\n",
    "2. Median income is 5.00 !!!!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Inspect data\r\n",
    "print(df.describe())\r\n",
    "print(df.describe(include=['O']))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Separate categorical and numerical features\r\n",
    "cat_feats = []\r\n",
    "num_feats = []\r\n",
    "for col in df.columns:\r\n",
    "    if col == 'ApprovalStatus':\r\n",
    "        pass # this is our target variable\r\n",
    "    elif df[col].dtype == object:\r\n",
    "        # print(col, 'is a cat feat')\r\n",
    "        cat_feats.append(col)\r\n",
    "    else:\r\n",
    "        # print(col, 'is a num feat')\r\n",
    "        num_feats.append(col)\r\n",
    "print('Categorical features:', cat_feats)\r\n",
    "print('Numerical features:', num_feats)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Visualize numerical features to find outliers\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "fig, ax = plt.subplots(ncols=len(num_feats), figsize=(30,5))\r\n",
    "for i in range(len(num_feats)):\r\n",
    "    _ = sns.boxplot(data=df, x=num_feats[i], ax=ax[i])\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Visualize ApprovalStatus in terms of cat feature\r\n",
    "for cat_feat in cat_feats:\r\n",
    "    # if df[cat_feat].nunique() < 7:\r\n",
    "        # _ = sns.catplot(data=df, x='ApprovalStatus', kind='count', col=cat_feat)\r\n",
    "        # plt.show()\r\n",
    "    print(pd.crosstab(index=df[cat_feat], columns=df['ApprovalStatus']))\r\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cat features value has no meaning we can infer on ....."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Base model in last notebook managed to get around 84% accuracy.<br>\r\n",
    "See how can we improve on that."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing\r\n",
    "1. Drop zipcode - so many\r\n",
    "2. Label encode cat features\r\n",
    "3. Mean impute num features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# separate cat and num features and drop ZipCode\r\n",
    "X_num = df.loc[:, num_feats]\r\n",
    "X_cat = df.loc[:, cat_feats]\r\n",
    "X_cat = X_cat.drop(['ZipCode'], axis=1)\r\n",
    "cat_feats.remove('ZipCode')\r\n",
    "y = df.loc[:,'ApprovalStatus']\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# try label encoding for categorical variables\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "for cat_feat in cat_feats:\r\n",
    "    le = LabelEncoder()\r\n",
    "    X_cat[cat_feat] = le.fit_transform(X_cat[cat_feat])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# median imputation for numerical features\r\n",
    "from sklearn.impute import SimpleImputer\r\n",
    "im = SimpleImputer(strategy='median')\r\n",
    "X_num = pd.DataFrame(im.fit_transform(X_num), columns=X_num.columns)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# concatenate X_cat and X_num --> X\r\n",
    "X = pd.concat([X_num, X_cat], axis=1)\r\n",
    "print(X.info())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# scale since all are are numeric\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "X = StandardScaler().fit_transform(X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build base model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# train:test = 90:10 w/ constant random state to duplicate\r\n",
    "from sklearn.model_selection import train_test_split \r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# fit and predict for base model\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "log_reg = LogisticRegression().fit(X_train, y_train)\r\n",
    "y_base_model = log_reg.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# View results for base model\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "# classification report\r\n",
    "print('Classification report')\r\n",
    "print(classification_report(y_test, y_base_model))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ROC of base model\r\n",
    "import matplotlib.pyplot as plt  \r\n",
    "from sklearn.metrics import plot_roc_curve\r\n",
    "plot_roc_curve(log_reg, X_test, y_test)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "5e57bd0e9122681100ff0c01a77d03a96c53183a268dc781647c7935a0e65936"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}